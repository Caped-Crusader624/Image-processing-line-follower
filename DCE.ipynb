{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Caped-Crusader624/Image-processing-line-follower/blob/main/DCE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXSCduUZtw5M"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from random import shuffle\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DADrl43YbFjb"
      },
      "source": [
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsRTn1SYc3EJ",
        "outputId": "a9b0a385-82d5-470a-c4b0-423a0187b3dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPC7hm71dNs9"
      },
      "source": [
        "#!unzip \"/content/gdrive/My Drive/LOL.zip\" -d \"/content/gdrive/My Drive/lol\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VAs6-ygAzqU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "#import pytorch_colors as colors\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPg4kvUHbIfo"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToPILImage(),transforms.Resize((512,512)),transforms.ToTensor()])\n",
        "batch_s = 16\n",
        "shuffle_dataset = True\n",
        "random_seed= 9\n",
        "filepath=\"/content/gdrive/My Drive/lol/our485/low/\"\n",
        "pretrain_dir=\"/content/gdrive/My Drive/snapshots/Epoch992.pth\"\n",
        "load_pretrain=False\n",
        "snapshots_folder=\"/content/gdrive/My Drive/snapshots/\"\n",
        "snapshot_iter=10\n",
        "display_iter=10\n",
        "num_workers=4\n",
        "val_batch_size=4\n",
        "train_batch_size=8\n",
        "num_epochs=200\n",
        "grad_clip_norm=0.1\n",
        "weight_decay=0.0001\n",
        "lr=1e-4\n",
        "lowlight_images_path=filepath\n",
        "graph=[]\n",
        "\n",
        "'''address=[]\n",
        "new=[]\n",
        "for file in os.listdir(filepath):\n",
        "    address.append(str(os.path.join(filepath,file)))\n",
        "    new.append(str(os.path.join(filepath,file[:-3]+\".jpg\")))\n",
        "\n",
        "for image in range(len(address)):\n",
        "    img_png = Image.open(address[image])\n",
        "  \n",
        "#The image object is used to save the image in jpg format\n",
        "    img_png.save(new[image])'''\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self):\n",
        "      self.transform=transform\n",
        "      self.img_folder=filepath\n",
        "      self.address=[]\n",
        "        \n",
        "        #for folder in os.listdir(self.img_folder):\n",
        "         #   self.folder_path=os.path.join(self.img_folder,folder)\n",
        "          #  for file in os.listdir(self.folder_path):\n",
        "           #     self.address.append(str(os.path.join(self.folder_path,file)))\n",
        "    \n",
        "      for file in os.listdir(self.img_folder):\n",
        "        if \".jpg\" in file:\n",
        "          self.address.append(str(os.path.join(self.img_folder,file)))\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.address)\n",
        " \n",
        "    def __getitem__(self,index):\n",
        "\n",
        "        image=cv2.imread(self.address[index])#[:,:,-1]\n",
        "        #image=data_lowlight.resize((512,512), Image.ANTIALIAS)\n",
        "        image=self.transform(image)\n",
        "        \n",
        "        #image=torch.div(image,255.0)\n",
        "\n",
        "        \n",
        "\n",
        "        #image = (np.asarray(image)/255.0) \n",
        "\t\t    #image = torch.from_numpy(image).float()\n",
        "\n",
        "\n",
        "        return image\n",
        "        \n",
        "class L_TV(nn.Module):\n",
        "    def __init__(self,TVLoss_weight=1):\n",
        "        super(L_TV,self).__init__()\n",
        "        self.TVLoss_weight = TVLoss_weight\n",
        "\n",
        "    def forward(self,x):\n",
        "        batch_size = x.size()[0]\n",
        "        h = x.size()[2]\n",
        "        w = x.size()[3]\n",
        "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
        "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
        "        h_t = torch.pow((x[:,:,1:,:]-x[:,:,:h-1,:]),2).sum()\n",
        "        w_t = torch.pow((x[:,:,:,1:]-x[:,:,:,:w-1]),2).sum()\n",
        "        return self.TVLoss_weight*2*(h_t/count_h+w_t/count_w)/batch_size\n",
        "        \n",
        "class L_spa(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.left=torch.tensor([[[[0,0,0],[-1,1,0],[0,0,0]]]]).float().cuda()\n",
        "        self.right=torch.tensor([[[[0,0,0],[0,1,-1],[0,0,0]]]]).float().cuda()\n",
        "        self.up=torch.tensor([[[[0,-1,0],[0,1,0],[0,0,0]]]]).float().cuda()\n",
        "        self.down=torch.tensor([[[[0,0,0],[0,1,0],[0,-1,0]]]]).float().cuda()\n",
        "        \n",
        "        self.left_w = nn.Parameter(data=self.left, requires_grad=False)\n",
        "        self.right_w= nn.Parameter(data=self.right, requires_grad=False)\n",
        "        self.up_w = nn.Parameter(data=self.up, requires_grad=False)\n",
        "        self.down_w= nn.Parameter(data=self.down, requires_grad=False)\n",
        "                \n",
        "        self.n=torch.nn.AvgPool2d(4)\n",
        "\n",
        "    def forward(self, x, y):#spatial loss\n",
        "        \n",
        "        x = torch.mean(x,1,keepdim=True)\n",
        "        y = torch.mean(y,1,keepdim=True)\n",
        "        \n",
        "        x = self.n(x)\n",
        "        y = self.n(y)\n",
        "        \n",
        "\n",
        "        orginal_left= nn.functional.conv2d(x , self.left_w, padding=[1],stride=[1])\n",
        "        orginal_right= nn.functional.conv2d(x , self.right_w, padding=1,stride=[1])\n",
        "        orginal_down= nn.functional.conv2d(x , self.down_w, padding=1,stride=[1])\n",
        "        orginal_up= nn.functional.conv2d(x , self.up_w, padding=1,stride=[1])\n",
        "    \n",
        "        enh_left= nn.functional.conv2d(y , self.left_w, padding=1,stride=[1])\n",
        "        enh_right= nn.functional.conv2d(y , self.right_w, padding=1,stride=[1])\n",
        "        enh_down= nn.functional.conv2d(y , self.down_w, padding=1,stride=[1])\n",
        "        enh_up= nn.functional.conv2d(y , self.up_w, padding=1,stride=[1])\n",
        "    \n",
        "        l_left=(torch.pow(orginal_left-enh_left,2))\n",
        "        l_right=(torch.pow(orginal_right-enh_right,2))\n",
        "        l_down=(torch.pow(orginal_down-enh_down,2))\n",
        "        l_up=(torch.pow(orginal_up-enh_up,2))\n",
        "    \n",
        "        l_spa= torch.mean(l_left+l_right+l_down+l_up)\n",
        "\n",
        "        return l_spa\n",
        "    \n",
        "class L_exp(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()    \n",
        "        self.pool = nn.AvgPool2d(16)\n",
        "        self.mean=0.6\n",
        "    def forward(self,y):\n",
        "        y = torch.mean(y,1,keepdim=True)\n",
        "        y=self.pool(y)\n",
        "        \n",
        "        d = torch.mean(torch.pow(torch.pow(y- torch.FloatTensor([self.mean] ).cuda(),2),0.5))\n",
        "        \n",
        "        return d\n",
        "    \n",
        "class L_color(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(L_color, self).__init__()\n",
        "    def forward(self, y):\n",
        "        r,g,b = torch.split(y , 1, dim=1)\n",
        "        Drg = torch.pow(r-g,2)\n",
        "        Drb = torch.pow(r-b,2)\n",
        "        Dgb = torch.pow(b-g,2)\n",
        "        k = torch.mean(Drg + Drb + Dgb)\n",
        "        return k  \n",
        "\n",
        "class enhance_net_nopool(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(enhance_net_nopool, self).__init__()\n",
        "\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\t\tnumber_f = 32\n",
        "\t\tself.e_conv1 = nn.Conv2d(3,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv3 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv4 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv6 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
        "\t\tself.e_conv7 = nn.Conv2d(number_f*2,24,3,1,1,bias=True) \n",
        "\n",
        "\t\tself.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
        "\t\tself.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "\n",
        "\n",
        "\t\t\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tx1 = self.relu(self.e_conv1(x))\n",
        "\t\tx2 = self.relu(self.e_conv2(x1))\n",
        "\t\tx3 = self.relu(self.e_conv3(x2))\n",
        "\t\tx4 = self.relu(self.e_conv4(x3))\n",
        "\n",
        "\t\tx5 = self.relu(self.e_conv5(torch.cat([x3,x4],1)))\n",
        "\t\tx6 = self.relu(self.e_conv6(torch.cat([x2,x5],1)))\n",
        "\n",
        "\t\tx_r = torch.tanh(self.e_conv7(torch.cat([x1,x6],1)))\n",
        "\t\tr1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 3, dim=1)\n",
        "\n",
        "\n",
        "\t\tx = x +r1*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r2*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r3*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
        "\t\tx = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
        "\t\tx = x + r6*(torch.pow(x,2)-x)\t\n",
        "\t\tx = x + r7*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image = x + r8*(torch.pow(x,2)-x)\n",
        "\t\tr = torch.cat([r1,r2,r3,r4,r5,r6,r7,r8],1)\n",
        "\t\treturn enhance_image,r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8buXD7bbKxR"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    \n",
        "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "    torch.cuda.empty_cache()\n",
        "    DCE_net = enhance_net_nopool().cuda()\n",
        "\n",
        "    DCE_net.apply(weights_init)\n",
        "    if load_pretrain == True:\n",
        "        DCE_net.load_state_dict(torch.load(pretrain_dir))\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(DCE_net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    \n",
        "    DCE_net.train()\n",
        "\n",
        "    L_col = L_color()\n",
        "    L_sp = L_spa()\n",
        "\n",
        "    L_ex = L_exp()\n",
        "    L_Tv = L_TV()\n",
        "\n",
        "\n",
        "    for epoch in range(9):\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"Epoch: \"+ str(epoch))\n",
        "        for iteration, img_lowlight in enumerate(train_loader):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            img_lowlight = img_lowlight.cuda()\n",
        "            torch.cuda.empty_cache()\n",
        "            #print('l'+str(img_lowlight.size()))\n",
        "            enhanced_image,r = DCE_net.forward(img_lowlight)\n",
        "            \n",
        "            #print(enhanced_image.size())\n",
        "            \n",
        "            Loss_tv = 15*L_Tv(r)\n",
        "\n",
        "            loss_s = torch.mean(L_sp(enhanced_image, img_lowlight))\n",
        "\n",
        "            loss_co = 0.075*torch.mean(L_col(enhanced_image))\n",
        "\n",
        "            loss_e = torch.mean(L_ex(enhanced_image))\n",
        "\t\t\t\n",
        "\t\t\t            \n",
        "            \n",
        "            # best_loss\n",
        "            loss =   10*(loss_s + loss_co + loss_e +Loss_tv)\n",
        "            #\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(DCE_net.parameters(),grad_clip_norm)\n",
        "            optimizer.step()\n",
        "                        \n",
        "            graph.append(loss)\n",
        "\n",
        "            if ((iteration+1) % display_iter) == 0:\n",
        "                print(\"Loss at iteration\", iteration+1, \":\", loss.item())\n",
        "            if ((iteration+1) % snapshot_iter) == 0 and not(math.isnan(loss)):\n",
        "                torch.save(DCE_net.state_dict(), snapshots_folder + \"Epoch#991\" + str(epoch) + '.pth')\n",
        "                plt.plot(range(len(graph)), graph, 'g', label='Training loss')\n",
        "                plt.title('model loss')\n",
        "                plt.ylabel('loss')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.legend(['train'], loc='upper left')\n",
        "                plt.show()\n",
        "            \n",
        "            \n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "ce7tiYF-bOEZ",
        "outputId": "4f6ee17a-f5a7-40b7-cdee-cc19dc9a1cf2"
      },
      "source": [
        "#stop this after epoch 0 is printed and run next cell, we need to validate using .pth not train. but dataloaders are in this cell\n",
        "graph=[]\n",
        "if __name__ == '__main__':\n",
        "    datasets=ImageDataset()\n",
        "    dataset_size=len(datasets)\n",
        "    indices = list(range(dataset_size))\n",
        "    \n",
        "    np.random.seed(9)\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[0:300], indices[300:]\n",
        "# Creating PT data samplers and loaders:\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "    \n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_s, sampler=train_sampler)\n",
        "    validation_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_s,sampler=valid_sampler)\n",
        "\n",
        "    if not os.path.exists(snapshots_folder):\n",
        "        os.mkdir(snapshots_folder)\n",
        "\n",
        "\n",
        "    train()\n",
        "    \n",
        "    # summarize history for loss\n",
        "    plt.plot(range(300*10), graph, 'g', label='Training loss')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c99f4d4dd888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-33fd99928e98>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mDCE_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance_net_nopool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mDCE_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzYlRlTbu3RG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "ec89a6f0-5b47-4807-b056-6600a62d6e2a"
      },
      "source": [
        "#validation testing(somethin wrong)(check this)\n",
        "validation_loader = torch.utils.data.DataLoader(datasets, batch_size=1,sampler=valid_sampler)\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "DCE_net=enhance_net_nopool().cuda()\n",
        "DCE_net_1 = enhance_net_nopool().cuda()\n",
        "\n",
        "DCE_net_1.load_state_dict(torch.load('/content/gdrive/My Drive/snapshots/Epoch99.pth'))\n",
        "DCE_net.load_state_dict(torch.load('/content/gdrive/My Drive/snapshots/Epoch#9903.pth'))\n",
        "\n",
        "result_path='/content/gdrive/My Drive/result' \n",
        "original_path='/content/gdrive/My Drive/original' \n",
        "twice_path='/content/gdrive/My Drive/twice'\n",
        "\n",
        "for iteration, img_lowlight in enumerate(validation_loader):\n",
        "  img_lowlight=img_lowlight.cuda()\n",
        "  current='image'+str(iteration)+'.jpg'\n",
        "  #img_lowlight=img_lowlight.cuda()*torch.FloatTensor([255] ).cuda()\n",
        "  enhanced_image1,_= DCE_net_1(img_lowlight)\n",
        "  torchvision.utils.save_image(enhanced_image1, os.path.join(result_path,current))\n",
        "\n",
        "  #enhanced_image=enhanced_image*torch.tensor([2]).cuda()\n",
        "\n",
        "\n",
        "  enhanced_image,_= DCE_net(img_lowlight)\n",
        "  torchvision.utils.save_image(enhanced_image, os.path.join(twice_path,current))\n",
        "\n",
        "  #img_lowlight=img_lowlight.cuda()*torch.FloatTensor([255] ).cuda()\n",
        "\n",
        "  torchvision.utils.save_image(img_lowlight, os.path.join(original_path,current))\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fd74f7b63a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtwice_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/twice'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_lowlight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mimg_lowlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_lowlight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-dfe29b8e90ef>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[:,:,-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m#image=data_lowlight.resize((512,512), Image.ANTIALIAS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERA6sIXdBzdi"
      },
      "source": [
        "  enhanced_image,r= DCE_net(img_lowlight.cuda())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWC4xo_YB5Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22dfdb8-eace-4993-b1ed-2e708b0c565f"
      },
      "source": [
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.0572, -0.0553, -0.0566,  ..., -0.0556, -0.0488, -0.0301],\n",
            "          [-0.0835, -0.1009, -0.1189,  ..., -0.1173, -0.0990, -0.0663],\n",
            "          [-0.1007, -0.1357, -0.1642,  ..., -0.1641, -0.1392, -0.0948],\n",
            "          ...,\n",
            "          [-0.1053, -0.1508, -0.1841,  ..., -0.1910, -0.1640, -0.1103],\n",
            "          [-0.0941, -0.1427, -0.1755,  ..., -0.1830, -0.1604, -0.1076],\n",
            "          [-0.0453, -0.0808, -0.1117,  ..., -0.1194, -0.1051, -0.0573]],\n",
            "\n",
            "         [[-0.1249, -0.1531, -0.1679,  ..., -0.1605, -0.1382, -0.1054],\n",
            "          [-0.1748, -0.2143, -0.2312,  ..., -0.2191, -0.1888, -0.1420],\n",
            "          [-0.1908, -0.2324, -0.2529,  ..., -0.2389, -0.2038, -0.1484],\n",
            "          ...,\n",
            "          [-0.1910, -0.2310, -0.2503,  ..., -0.2416, -0.2052, -0.1470],\n",
            "          [-0.1735, -0.2065, -0.2208,  ..., -0.2139, -0.1861, -0.1356],\n",
            "          [-0.1234, -0.1475, -0.1567,  ..., -0.1564, -0.1445, -0.0998]],\n",
            "\n",
            "         [[-0.1083, -0.1457, -0.1505,  ..., -0.1366, -0.1114, -0.0767],\n",
            "          [-0.1487, -0.1877, -0.1942,  ..., -0.1727, -0.1403, -0.0995],\n",
            "          [-0.1686, -0.2151, -0.2296,  ..., -0.2061, -0.1674, -0.1200],\n",
            "          ...,\n",
            "          [-0.1633, -0.2099, -0.2269,  ..., -0.2113, -0.1761, -0.1296],\n",
            "          [-0.1417, -0.1878, -0.2071,  ..., -0.1973, -0.1706, -0.1265],\n",
            "          [-0.1023, -0.1381, -0.1598,  ..., -0.1568, -0.1373, -0.0969]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0660, -0.0922, -0.1115,  ..., -0.1095, -0.0921, -0.0587],\n",
            "          [-0.1010, -0.1302, -0.1608,  ..., -0.1609, -0.1384, -0.0993],\n",
            "          [-0.1196, -0.1607, -0.2017,  ..., -0.2022, -0.1729, -0.1226],\n",
            "          ...,\n",
            "          [-0.1163, -0.1589, -0.2007,  ..., -0.2083, -0.1807, -0.1283],\n",
            "          [-0.1018, -0.1395, -0.1772,  ..., -0.1857, -0.1634, -0.1142],\n",
            "          [-0.0699, -0.1020, -0.1293,  ..., -0.1330, -0.1160, -0.0838]],\n",
            "\n",
            "         [[-0.0857, -0.1058, -0.1223,  ..., -0.1160, -0.0992, -0.0599],\n",
            "          [-0.1149, -0.1309, -0.1643,  ..., -0.1609, -0.1393, -0.0996],\n",
            "          [-0.1360, -0.1649, -0.2117,  ..., -0.2113, -0.1837, -0.1385],\n",
            "          ...,\n",
            "          [-0.1383, -0.1731, -0.2253,  ..., -0.2342, -0.2055, -0.1594],\n",
            "          [-0.1183, -0.1550, -0.2013,  ..., -0.2123, -0.1902, -0.1500],\n",
            "          [-0.0786, -0.1162, -0.1537,  ..., -0.1659, -0.1504, -0.1159]],\n",
            "\n",
            "         [[-0.1428, -0.1744, -0.1930,  ..., -0.1935, -0.1839, -0.1480],\n",
            "          [-0.1776, -0.2109, -0.2397,  ..., -0.2394, -0.2230, -0.1754],\n",
            "          [-0.2004, -0.2419, -0.2783,  ..., -0.2762, -0.2518, -0.1957],\n",
            "          ...,\n",
            "          [-0.2042, -0.2471, -0.2854,  ..., -0.2895, -0.2656, -0.2064],\n",
            "          [-0.1987, -0.2390, -0.2701,  ..., -0.2733, -0.2526, -0.1989],\n",
            "          [-0.1732, -0.2096, -0.2355,  ..., -0.2334, -0.2099, -0.1448]]]],\n",
            "       device='cuda:0', grad_fn=<CatBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvT45Ab0fd92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da58676e-7a97-4578-8a6c-e599b347265e"
      },
      "source": [
        "enhanced_image,r= DCE_net_1(img_lowlight.cuda())\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.2202, -0.2638, -0.2847,  ..., -0.2625, -0.2375, -0.1892],\n",
            "          [-0.2644, -0.2784, -0.2877,  ..., -0.2678, -0.2546, -0.2345],\n",
            "          [-0.2850, -0.2879, -0.2931,  ..., -0.2743, -0.2673, -0.2611],\n",
            "          ...,\n",
            "          [-0.2378, -0.2392, -0.2464,  ..., -0.2676, -0.2638, -0.2621],\n",
            "          [-0.2151, -0.2241, -0.2390,  ..., -0.2643, -0.2549, -0.2444],\n",
            "          [-0.1787, -0.2140, -0.2381,  ..., -0.2628, -0.2443, -0.2056]],\n",
            "\n",
            "         [[-0.2277, -0.2729, -0.2939,  ..., -0.2712, -0.2458, -0.1980],\n",
            "          [-0.2738, -0.2894, -0.2989,  ..., -0.2785, -0.2650, -0.2435],\n",
            "          [-0.2942, -0.2989, -0.3042,  ..., -0.2854, -0.2783, -0.2706],\n",
            "          ...,\n",
            "          [-0.2463, -0.2488, -0.2562,  ..., -0.2782, -0.2743, -0.2709],\n",
            "          [-0.2232, -0.2334, -0.2488,  ..., -0.2747, -0.2648, -0.2526],\n",
            "          [-0.1864, -0.2221, -0.2466,  ..., -0.2720, -0.2531, -0.2144]],\n",
            "\n",
            "         [[-0.2490, -0.2838, -0.3007,  ..., -0.2815, -0.2604, -0.2230],\n",
            "          [-0.2839, -0.2936, -0.3015,  ..., -0.2850, -0.2736, -0.2589],\n",
            "          [-0.3006, -0.3015, -0.3060,  ..., -0.2913, -0.2847, -0.2813],\n",
            "          ...,\n",
            "          [-0.2627, -0.2631, -0.2693,  ..., -0.2858, -0.2821, -0.2820],\n",
            "          [-0.2443, -0.2511, -0.2632,  ..., -0.2830, -0.2748, -0.2671],\n",
            "          [-0.2128, -0.2439, -0.2635,  ..., -0.2837, -0.2685, -0.2359]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2178, -0.2588, -0.2795,  ..., -0.2573, -0.2319, -0.1852],\n",
            "          [-0.2601, -0.2736, -0.2829,  ..., -0.2631, -0.2496, -0.2298],\n",
            "          [-0.2803, -0.2833, -0.2885,  ..., -0.2701, -0.2628, -0.2566],\n",
            "          ...,\n",
            "          [-0.2325, -0.2341, -0.2414,  ..., -0.2630, -0.2590, -0.2570],\n",
            "          [-0.2095, -0.2187, -0.2340,  ..., -0.2593, -0.2497, -0.2389],\n",
            "          [-0.1741, -0.2088, -0.2330,  ..., -0.2574, -0.2385, -0.2019]],\n",
            "\n",
            "         [[-0.2228, -0.2666, -0.2881,  ..., -0.2650, -0.2394, -0.1912],\n",
            "          [-0.2678, -0.2836, -0.2934,  ..., -0.2728, -0.2589, -0.2369],\n",
            "          [-0.2884, -0.2933, -0.2988,  ..., -0.2797, -0.2724, -0.2643],\n",
            "          ...,\n",
            "          [-0.2397, -0.2428, -0.2503,  ..., -0.2723, -0.2685, -0.2650],\n",
            "          [-0.2164, -0.2274, -0.2428,  ..., -0.2688, -0.2590, -0.2465],\n",
            "          [-0.1804, -0.2157, -0.2403,  ..., -0.2656, -0.2465, -0.2066]],\n",
            "\n",
            "         [[-0.2212, -0.2575, -0.2752,  ..., -0.2557, -0.2341, -0.1930],\n",
            "          [-0.2583, -0.2681, -0.2762,  ..., -0.2595, -0.2479, -0.2323],\n",
            "          [-0.2754, -0.2762, -0.2808,  ..., -0.2656, -0.2591, -0.2552],\n",
            "          ...,\n",
            "          [-0.2359, -0.2367, -0.2432,  ..., -0.2597, -0.2563, -0.2559],\n",
            "          [-0.2167, -0.2243, -0.2370,  ..., -0.2571, -0.2493, -0.2409],\n",
            "          [-0.1845, -0.2162, -0.2369,  ..., -0.2575, -0.2421, -0.2070]]]],\n",
            "       device='cuda:0', grad_fn=<CatBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6NJti3lU4B7"
      },
      "source": [
        "print(img_lowlight*torch.tensor([255]).cuda())\n",
        "img_lowlight=img_lowlight*torch.tensor([255]).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-vldG6VT0w"
      },
      "source": [
        "print(enhanced_image.cuda()*img_lowlight.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g05QMp_vVb7"
      },
      "source": [
        "s_path='/content/gdrive/My Drive/path'\n",
        "for iteration, img_lowlight in enumerate(train_loader):\n",
        "  current='image'+str(iteration)+'.jpg'\n",
        "  img_low=img_lowlight.cuda()\n",
        "  img_low=img_low*torch.FloatTensor([255] ).cuda()\n",
        "  torchvision.utils.save_image(img_low, os.path.join(s_path,current))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}